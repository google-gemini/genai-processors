{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBxPnCcuuAuO"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 DeepMind Technologies Limited. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "metadata": {
        "id": "x8Qd6mWRuFHz"
      },
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-gemini/genai-processors/blob/main/notebooks/function_calling.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "A8yIcf81uf_s"
      },
      "cell_type": "markdown",
      "source": [
        "# Function Calling with Processors üìû\n",
        "\n",
        "The GenAI Processor library provides a processor to run Function Calls with any\n",
        "model that can produce GenAI FunctionCall parts. This notebook provides a\n",
        "step-by-step guide on how to do this.\n",
        "\n",
        ""
      ]
    },
    {
      "metadata": {
        "id": "rYqU_6n4v-dQ"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. üõ†Ô∏è Setup\n",
        "\n",
        "First, install the GenAI Processors library:"
      ]
    },
    {
      "metadata": {
        "id": "bDal7EHPwCDk"
      },
      "cell_type": "code",
      "source": [
        "!pip install genai-processors"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cDttR4ybwPxM"
      },
      "cell_type": "markdown",
      "source": [
        "### API Key\n",
        "\n",
        "You will need an API key to call the Genai models in this notebook. If you have\n",
        "not done so already, obtain your API key from Google AI Studio, and import it as\n",
        "a secret in Colab (recommended) or directly set it below."
      ]
    },
    {
      "metadata": {
        "id": "rp0isW_4wNSZ"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "wWoaB7Xw1I-1"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. üëÜ Define the functions to be called\n",
        "\n",
        "The Tool definition will be automatically derived from the function signature.\n",
        "So it is advised to have a good docstring that covers the arguments and the\n",
        "returned value. We use introspection though and the model will see the function\n",
        "schema even if docstring is missing."
      ]
    },
    {
      "metadata": {
        "id": "GuSwrv5D1pAy"
      },
      "cell_type": "code",
      "source": [
        "def get_weather(location: str) -> str:\n",
        "  \"\"\"Returns the weather information.\n",
        "\n",
        "  The weather information will contain the temperature in Celsius.\n",
        "\n",
        "  Args:\n",
        "    location: name of the city, region or place where the weather is requested.\n",
        "\n",
        "  Returns:\n",
        "    a string describing the weather at the provided location.\n",
        "  \"\"\"\n",
        "  return f'Weather in {location} is 21 degrees celcius and rainy'\n",
        "\n",
        "\n",
        "def to_fahrenheit(celsius: int) -> str:\n",
        "  \"\"\"Returns fahrenheit temperature given the value in celsius.\"\"\"\n",
        "  fahrenheit = (celsius * 9 / 5) + 32\n",
        "  return fahrenheit"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "pklvojGQ2_A9"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. ‚ú® Create a function calling processor\n",
        "\n",
        "We will use here the Gemini API for our model. We first configure the model to\n",
        "output function calls for our two python functions.\n",
        "\n",
        "If you choose other models, you will need to configure them to make sure they\n",
        "can output function calls.\n",
        "\n",
        "**NOTE**: we need to disable the automatic function calling that implements\n",
        "another function calling inside the Genai SDK to avoid duplicate function calls.\n",
        "Using this processor-based function calling is needed for other services that do\n",
        "not offer automatic function calling. It also opens up the mechanics of function\n",
        "calling for ad-hoc development (e.g. different ways of handling errors)."
      ]
    },
    {
      "metadata": {
        "id": "8ArjWNMB3Nyn"
      },
      "cell_type": "code",
      "source": [
        "from genai_processors.core import genai_model\n",
        "from google.genai import types as genai_types\n",
        "\n",
        "# Initialize the GenAI model processor\n",
        "# Replace 'gemini-2.5-flash' with your desired model name\n",
        "genai_processor = genai_model.GenaiModel(\n",
        "    api_key=API_KEY,\n",
        "    model_name=\"gemini-2.5-flash\",\n",
        "    generate_content_config=genai_types.GenerateContentConfig(\n",
        "        tools=[get_weather, to_fahrenheit],\n",
        "        automatic_function_calling=genai_types.AutomaticFunctionCallingConfig(\n",
        "            disable=True\n",
        "        ),\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "SPwAeFQh4CXF"
      },
      "cell_type": "markdown",
      "source": [
        "Then adding function calling is done as follows:"
      ]
    },
    {
      "metadata": {
        "id": "UC3jcXXE4IMP"
      },
      "cell_type": "code",
      "source": [
        "from genai_processors.core import function_calling\n",
        "\n",
        "fc = function_calling.FunctionCalling(\n",
        "    genai_processor,\n",
        "    fns=[get_weather, to_fahrenheit],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "btH0h1Gq47ra"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. ‚ñ∂Ô∏è Run the function calling processor\n",
        "\n",
        "The function calling processor is typically used on a stream of user prompts."
      ]
    },
    {
      "metadata": {
        "id": "TXDcjJXg5A_i"
      },
      "cell_type": "code",
      "source": [
        "from genai_processors import streams\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()  # Needed to run async loops in Colab\n",
        "\n",
        "input_stream = streams.stream_content(\n",
        "    ['What is the weather in Cherbourg? Give the temperature in Fahrenheit.']\n",
        ")\n",
        "\n",
        "async for part in fc(input_stream):\n",
        "  if not part.substream_name:\n",
        "    # default substream - contains what the user would see.\n",
        "    print(f'\\033[0m {part.text}', flush=True, end='')\n",
        "\n",
        "  if part.substream_name:\n",
        "    # subtream_name = \"function_call\" / internal function calls.\n",
        "    if part.function_call:\n",
        "      print(\n",
        "          f'\\033[96m FC: {part.function_call.name}: {part.function_call.args}',\n",
        "          flush=True,\n",
        "      )\n",
        "    elif part.function_response:\n",
        "      print(\n",
        "          f'\\033[96m FR: {part.function_response.response}',\n",
        "          flush=True,\n",
        "      )"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      }
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
